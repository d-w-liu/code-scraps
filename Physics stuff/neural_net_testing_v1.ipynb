{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import awkward\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\program files (x86)\\python 3.7\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "noise_data_x = generate_distribution(events = 5000, peak = 0.0, width = 10.0, height = 1.0, correlation = 0.0, width_factor = 1.0)\n",
    "noise_data_y = generate_distribution(events = 5000, peak = 0.0, width = 10.0, height = 1.2, correlation = 0.0, width_factor = 1.0)\n",
    "noise_data_z = generate_distribution(events = 5000, peak = 0.0, width = 10.0, height = 0.8, correlation = 0.0, width_factor = 1.0)\n",
    "\n",
    "signal_data_x = generate_distribution(events = 1500, peak = 20.0, width = 10.0, height = 3.0, correlation = 0.4, width_factor = 1.0)\n",
    "signal_data_y = generate_distribution(events = 1500, peak = 20.0, width = 10.0, height = 3.0, correlation = 0.4, width_factor = 1.0)\n",
    "signal_data_z = generate_distribution(events = 1500, peak = 20.0, width = 10.0, height = 3.0, correlation = 0.4, width_factor = 1.0)\n",
    "\n",
    "noise_data_x = noise_data_x[0].tolist()\n",
    "noise_data_y = noise_data_y[0].tolist()\n",
    "noise_data_z = noise_data_z[0].tolist()\n",
    "\n",
    "signal_data_x = signal_data_x[0].tolist()\n",
    "signal_data_y = signal_data_y[0].tolist()\n",
    "signal_data_z = signal_data_z[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine our lists our lists:\n",
    "\n",
    "data_x = noise_data_x + signal_data_x\n",
    "data_y = noise_data_y + signal_data_y\n",
    "data_z = noise_data_z + signal_data_z\n",
    "noise_list = [0] * 5000\n",
    "signal_list = [1] * 1500\n",
    "soaring = noise_list + signal_list \n",
    "\n",
    "# Construct a pandas dataframe with all our data:\n",
    "\n",
    "data = {'var_1':data_x, 'var_2':data_y, 'var_3':data_z, 'sn':soaring}\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data.drop('sn', axis=1)\n",
    "output_data = data['sn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_test, output_train, output_test = train_test_split(input_data, output_data)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(input_train)\n",
    "\n",
    "input_train = scaler.transform(input_train)\n",
    "input_test = scaler.transform(input_test)\n",
    "\n",
    "neural_network = MLPClassifier(hidden_layer_sizes=(50,50), activation='tanh', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(50, 50), max_iter=500)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.fit(input_train, output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = neural_network.predict(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1234    0]\n",
      " [   0  391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1234\n",
      "           1       1.00      1.00      1.00       391\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(output_test,predictions))\n",
    "print(classification_report(output_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.72456416 -0.95885676 -0.47871387]\n",
      " [-0.19230635  0.34954655 -1.22553547]\n",
      " [-0.6013945  -1.2759914   0.03312678]\n",
      " ...\n",
      " [ 1.61000917  1.20691074  1.94415955]\n",
      " [ 0.2894575  -0.23897526 -1.13865026]\n",
      " [ 1.84773025  1.57034862  2.25096794]]\n"
     ]
    }
   ],
   "source": [
    "print(input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distribution(events, peak, width, height, correlation, width_factor):\n",
    "    x_interval = np.array([peak - (width/2), peak + (width/2)])\n",
    "    y_interval = np.array([0, height])\n",
    "    vector = np.vstack((x_interval, y_interval)).T\n",
    "\n",
    "    means = lambda x, y : [x.mean(), y.mean()]\n",
    "    stdvs = lambda x, y : [x.std() / width_factor, y.std() / width_factor]\n",
    "    covs = [[stdvs(x_interval, y_interval)[0]**2, stdvs(x_interval, y_interval)[0] * stdvs(x_interval, y_interval)[1] * correlation],\n",
    "            [stdvs(x_interval, y_interval)[1] * stdvs(x_interval, y_interval)[1] * correlation, stdvs(x_interval, y_interval)[1]**2]]\n",
    "\n",
    "    generated_data = np.random.multivariate_normal(means(x_interval, y_interval), covs, events).T\n",
    "\n",
    "    return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
